{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yTjmmhtFAFN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RlsAEKmX44s",
        "outputId": "177b2885-547f-449e-d263-e02665c276c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gradio rake-nltk PyPDF2 pymupdf4llm nltk groq langchain-community chromadb langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import pymupdf4llm\n",
        "import numpy as np\n",
        "import re\n",
        "from rake_nltk import Rake\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFaqAnbaFKWP",
        "outputId": "af1ca798-81f9-4ef3-ea57-e24bdfee5fe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_cv=\"\"\"\n",
        "\n",
        "You are a highly intelligent assistant tasked with analyzing CVs and creating concise, structured summaries optimized for comparing with job descriptions.\n",
        "\n",
        "Your goal is to extract and organize key details into specific categories. Structure your response as follows:\n",
        "\n",
        "1. **Professional Summary**: Provide a Five-sentences max overview of the candidate’s career focus, expertise, and achievements.\n",
        "2. **Key Skills and Expertise**: Enumerate the candidate's main skills, including technical skills (e.g., programming languages, tools,frameworks, services) and non-technical skills (e.g., leadership, communication).\n",
        "3. **Work Experience**:\n",
        "   - For each role, include:\n",
        "     - Job Title.\n",
        "     - Organization Name.\n",
        "     - Duration of Employment.\n",
        "     - Key responsibilities and accomplishments.\n",
        "4. **Technologies and Tools**: List every software, programming languages, frameworks,API service, and tools the candidate has experience with.\n",
        "5. **Education**: Summarize degrees, fields of study, and institutions attended.\n",
        "6. **Certifications and Training**: Highlight any certifications, courses, or training programs completed.\n",
        "7. **Languages**: Mention languages the candidate knows and their proficiency levels.\n",
        "8. **Projects**: Include significant projects or achievements relevant to the candidate's profile.\n",
        "9. **Keywords**: Extract important keywords that characterize the candidate’s expertise.\n",
        "\n",
        "Focus on clarity and precision in each section to ensure a well-structured summary. Here's the CV content:\n",
        "\n",
        "{content}\n",
        "\n",
        "Respond in the requested structured format.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "0AwAhcbQFKYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GROQ_API_KEY=\"gsk_uas1v...\"\n",
        "\n",
        "from groq import Groq\n",
        "\n",
        "def Summarize_job_text(content,prompt):\n",
        "    \"\"\"\n",
        "    Summarize a table using an LLM.\n",
        "    \"\"\"\n",
        "    client = Groq(api_key=GROQ_API_KEY)\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"you are a helpful assistant.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt.format(content=content),\n",
        "            }\n",
        "        ],\n",
        "        model=\"llama3-8b-8192\",\n",
        "        temperature=0,\n",
        "        max_tokens=2048,\n",
        "        top_p=1,\n",
        "    )\n",
        "\n",
        "\n",
        "    return chat_completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "0TMW-tAjWh66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "from langchain.schema.document import Document\n",
        "import uuid\n",
        "import pandas as pd\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import JinaEmbeddings"
      ],
      "metadata": {
        "id": "x4viKjzpFKcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unzip the db\n",
        "!unzip ./job_chroma_db.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7PXahLbFnhI",
        "outputId": "57165298-176a-42cc-d21e-5dd2f70942dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./job_chroma_db.zip\n",
            "   creating: content/job_chroma_db/\n",
            "  inflating: content/job_chroma_db/chroma.sqlite3  \n",
            "   creating: content/job_chroma_db/20bd1a1b-1584-482f-8742-5ee07f27d823/\n",
            "  inflating: content/job_chroma_db/20bd1a1b-1584-482f-8742-5ee07f27d823/link_lists.bin  \n",
            "  inflating: content/job_chroma_db/20bd1a1b-1584-482f-8742-5ee07f27d823/header.bin  \n",
            "  inflating: content/job_chroma_db/20bd1a1b-1584-482f-8742-5ee07f27d823/index_metadata.pickle  \n",
            "  inflating: content/job_chroma_db/20bd1a1b-1584-482f-8742-5ee07f27d823/length.bin  \n",
            "  inflating: content/job_chroma_db/20bd1a1b-1584-482f-8742-5ee07f27d823/data_level0.bin  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = JinaEmbeddings(\n",
        "    jina_api_key=\"jina_71a2d1c8cf884d6593a35a6a5d89ad2fp2BEEYkIHuIpXMXv7PIXHfFOk5vU\",\n",
        "    model_name=\"jina-embeddings-v3\"\n",
        ")"
      ],
      "metadata": {
        "id": "GlPklxx1F-OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the vectorstore\n",
        "vectorstore = Chroma(\n",
        "    persist_directory=\"./content/job_chroma_db\",\n",
        "    embedding_function=embedding_model\n",
        ")"
      ],
      "metadata": {
        "id": "q9K49pcZFe87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfbc3b08-0f82-4966-d1df-40189a741409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-7912392b0fd6>:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
            "  vectorstore = Chroma(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_markdown = pymupdf4llm.to_markdown(\"/content/Ismail-Oubah-EnglishCV.pdf\", page_chunks=True)\n",
        "cv_text = \" \".join([chunk['text'] for chunk in cv_markdown])\n",
        "\n",
        "# 2. Generate structured summary\n",
        "cv_summary = Summarize_job_text(cv_text, prompt_cv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTG2vtoW2VuU",
        "outputId": "11067946-c63b-4758-aa41-d80e1feca4ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/Ismail-Oubah-EnglishCV.pdf...\n",
            "[                                        ] (0/1)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b========================================\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b[========================================] (1/1)\b\b\b\b\b\b\b]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8VaKj6fh4G-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = vectorstore.similarity_search_with_score(cv_summary, k=3)"
      ],
      "metadata": {
        "id": "uP7JPIOe2YIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document=results[0][0]"
      ],
      "metadata": {
        "id": "do4tmQfj4KIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document.page_content"
      ],
      "metadata": {
        "id": "WEAoW-7246Zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = vectorstore._collection.get(include=['documents'])"
      ],
      "metadata": {
        "id": "qHsnLOXiGTRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_cv_and_recommend(cv_file, interests):\n",
        "    \"\"\"End-to-end processing pipeline with proper score conversion\"\"\"\n",
        "    try:\n",
        "        cv_markdown = pymupdf4llm.to_markdown(cv_file.name, page_chunks=True)\n",
        "        cv_text = \" \".join([chunk['text'] for chunk in cv_markdown])\n",
        "\n",
        "        cv_summary = Summarize_job_text(cv_text, prompt_cv)\n",
        "\n",
        "        # 3. Semantic search (get raw scores)\n",
        "        results = vectorstore.similarity_search_with_score(cv_summary, k=50)\n",
        "\n",
        "        # 4. Convert to percentages\n",
        "        processed = []\n",
        "        for doc, score in results:\n",
        "            # Convert cosine distance to similarity percentage\n",
        "            embedding_score = (1 - score) * 100\n",
        "\n",
        "            processed.append({\n",
        "                \"Document\": doc,\n",
        "                \"Embedding Score\": embedding_score,\n",
        "                \"Raw Score\": score\n",
        "            })\n",
        "\n",
        "        # 5. Calculate interest similarity\n",
        "        job_titles = [p[\"Document\"].metadata[\"job_title\"] for p in processed]\n",
        "        interest_scores = calculate_interest_similarity(interests, job_titles) * 100\n",
        "\n",
        "        # 6. Combine scores\n",
        "        for i, p in enumerate(processed):\n",
        "            p[\"Interest Score\"] = interest_scores[i]\n",
        "            p[\"Combined Score\"] = (0.7 * p[\"Embedding Score\"]) + (0.3 * p[\"Interest Score\"])\n",
        "\n",
        "        # 7. Sort and format results\n",
        "        processed.sort(key=lambda x: x[\"Combined Score\"], reverse=True)\n",
        "\n",
        "        # Build final dataframe\n",
        "        results_df = pd.DataFrame([{\n",
        "            \"Title\": p[\"Document\"].metadata.get(\"job_title\", \"N/A\"),\n",
        "            \"Company\": p[\"Document\"].metadata.get(\"company\", \"N/A\"),\n",
        "            \"Match %\": f\"{p['Combined Score']:.1f}%\",\n",
        "            \"Skills Match\": f\"{p['Embedding Score']:.1f}%\",\n",
        "            \"Interest Match\": f\"{p['Interest Score']:.1f}%\",\n",
        "            \"Link\": p[\"Document\"].metadata.get(\"job_link\", \"#\"),\n",
        "            \"summary\": p['Document'].page_content\n",
        "        } for p in processed[:50]])  # Show top 20\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    except Exception as e:\n",
        "        return pd.DataFrame({\"Error\": [str(e)]})\n",
        "\n",
        "def calculate_interest_similarity(interests, job_titles):\n",
        "    \"\"\"Calculate TF-IDF similarity between interests and job titles\"\"\"\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(job_titles + [interests])\n",
        "    return cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])[0]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qdXbjb5NGboI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio Interface\n",
        "with gr.Blocks(title=\"Job Matcher\", theme=gr.themes.Soft()) as app:\n",
        "    gr.Markdown(\"## 🔍 AI-Powered Job Matching Engine\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### 📤 Your Profile\")\n",
        "            cv_upload = gr.File(label=\"Upload your CV (PDF)\", file_types=[\".pdf\"])\n",
        "            interests_input = gr.Textbox(\n",
        "                label=\"Career Interests (comma-separated)\",\n",
        "                placeholder=\"e.g.: Machine Learning, Data Analysis, Cloud Computing\"\n",
        "            )\n",
        "            submit_btn = gr.Button(\"Find Best Matches\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            gr.Markdown(\"### 🏆 Top Recommendations\")\n",
        "            results_table = gr.Dataframe(\n",
        "                headers=[\"Title\", \"Company\", \"Match %\", \"Skills Match\", \"Interest Match\", \"Link\",\"summary\"],\n",
        "                datatype=[\"str\", \"str\", \"str\", \"str\", \"str\", \"str\",\"str\"],\n",
        "                interactive=False,\n",
        "                wrap=True\n",
        "            )\n",
        "\n",
        "    submit_btn.click(\n",
        "        fn=process_cv_and_recommend,\n",
        "        inputs=[cv_upload, interests_input],\n",
        "        outputs=results_table\n",
        "    )\n",
        "\n",
        "    if __name__ == \"__main__\":\n",
        "       app.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "zo6Uem3zGv1E",
        "outputId": "d4537cdf-a694-4bb5-b5e1-8107e87eb451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c59343ef59baf9e1a8.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c59343ef59baf9e1a8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}